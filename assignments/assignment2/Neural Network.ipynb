{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.321349, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302274, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302291, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302292, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302303, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302307, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302281, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302286, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302307, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302290, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2, num_epochs=10)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x115635950>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum=0.99), learning_rate_decay=0.99, num_epochs=5)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.306041, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278204, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275590, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275254, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274997, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum=0.99), learning_rate=1e-4, learning_rate_decay=0.99, num_epochs=5)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.273015, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.408223, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0.3 * 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(momentum=0.99), learning_rate=3e-1, num_epochs=20, batch_size=100)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "Loss: 2.279244, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277242, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272600, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.275299, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.375942, Train accuracy: 0.182000, val accuracy: 0.160000\n",
      "Loss: 2.277558, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.275463, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.271526, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272537, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.321613, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274739, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272019, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.269923, Train accuracy: 0.176000, val accuracy: 0.230000\n",
      "Loss: 2.271793, Train accuracy: 0.180000, val accuracy: 0.200000\n",
      "Loss: 2.303536, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.273580, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.273073, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.271014, Train accuracy: 0.183000, val accuracy: 0.250000\n",
      "Loss: 2.275681, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.313059, Train accuracy: 0.174000, val accuracy: 0.230000\n",
      "Loss: 2.273762, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272805, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272764, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.275440, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293141, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.250240, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.242198, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234680, Train accuracy: 0.181000, val accuracy: 0.220000\n",
      "Loss: 2.232785, Train accuracy: 0.189000, val accuracy: 0.180000\n",
      "Loss: 2.273738, Train accuracy: 0.180000, val accuracy: 0.140000\n",
      "Loss: 2.243321, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.236215, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.227043, Train accuracy: 0.192000, val accuracy: 0.190000\n",
      "Loss: 2.214277, Train accuracy: 0.202000, val accuracy: 0.190000\n",
      "Loss: 2.225904, Train accuracy: 0.212000, val accuracy: 0.190000\n",
      "Loss: 2.234653, Train accuracy: 0.184000, val accuracy: 0.220000\n",
      "Loss: 2.228113, Train accuracy: 0.181000, val accuracy: 0.230000\n",
      "Loss: 2.204453, Train accuracy: 0.198000, val accuracy: 0.170000\n",
      "Loss: 2.171527, Train accuracy: 0.246000, val accuracy: 0.260000\n",
      "Loss: 2.175099, Train accuracy: 0.272000, val accuracy: 0.280000\n",
      "Loss: 2.229941, Train accuracy: 0.179000, val accuracy: 0.230000\n",
      "Loss: 2.222293, Train accuracy: 0.187000, val accuracy: 0.260000\n",
      "Loss: 2.186235, Train accuracy: 0.225000, val accuracy: 0.210000\n",
      "Loss: 2.160865, Train accuracy: 0.269000, val accuracy: 0.270000\n",
      "Loss: 2.158278, Train accuracy: 0.332000, val accuracy: 0.280000\n",
      "Loss: 2.226760, Train accuracy: 0.182000, val accuracy: 0.230000\n",
      "Loss: 2.209699, Train accuracy: 0.192000, val accuracy: 0.200000\n",
      "Loss: 2.182049, Train accuracy: 0.231000, val accuracy: 0.220000\n",
      "Loss: 2.123897, Train accuracy: 0.291000, val accuracy: 0.310000\n",
      "Loss: 2.111413, Train accuracy: 0.372000, val accuracy: 0.290000\n",
      "Loss: 2.241243, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.230520, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.223895, Train accuracy: 0.184000, val accuracy: 0.220000\n",
      "Loss: 2.222667, Train accuracy: 0.185000, val accuracy: 0.190000\n",
      "Loss: 2.272121, Train accuracy: 0.214000, val accuracy: 0.190000\n",
      "Loss: 2.231170, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.222898, Train accuracy: 0.184000, val accuracy: 0.220000\n",
      "Loss: 2.213286, Train accuracy: 0.196000, val accuracy: 0.200000\n",
      "Loss: 2.193478, Train accuracy: 0.202000, val accuracy: 0.180000\n",
      "Loss: 2.179408, Train accuracy: 0.229000, val accuracy: 0.220000\n",
      "Loss: 2.223526, Train accuracy: 0.182000, val accuracy: 0.220000\n",
      "Loss: 2.214576, Train accuracy: 0.185000, val accuracy: 0.200000\n",
      "Loss: 2.180966, Train accuracy: 0.207000, val accuracy: 0.190000\n",
      "Loss: 2.135061, Train accuracy: 0.266000, val accuracy: 0.250000\n",
      "Loss: 2.039867, Train accuracy: 0.307000, val accuracy: 0.270000\n",
      "Loss: 2.217840, Train accuracy: 0.183000, val accuracy: 0.200000\n",
      "Loss: 2.205279, Train accuracy: 0.193000, val accuracy: 0.220000\n",
      "Loss: 2.160360, Train accuracy: 0.240000, val accuracy: 0.230000\n",
      "Loss: 2.057125, Train accuracy: 0.297000, val accuracy: 0.270000\n",
      "Loss: 1.915487, Train accuracy: 0.409000, val accuracy: 0.290000\n",
      "Loss: 2.214594, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.188276, Train accuracy: 0.201000, val accuracy: 0.200000\n",
      "Loss: 2.128423, Train accuracy: 0.281000, val accuracy: 0.300000\n",
      "Loss: 2.030966, Train accuracy: 0.365000, val accuracy: 0.320000\n",
      "Loss: 1.878442, Train accuracy: 0.437000, val accuracy: 0.350000\n",
      "Loss: 2.320833, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.312386, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295145, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280343, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.326261, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.315027, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.305868, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289333, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278156, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.329186, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.307206, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.297994, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.283319, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279466, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.320279, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302747, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293469, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281441, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278856, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.310198, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299235, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.290452, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279683, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279004, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301913, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295009, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289843, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277084, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.260706, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.248951, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291288, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285060, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.270782, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.255139, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.255376, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.285982, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278860, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.263046, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.248741, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.259217, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.282663, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274792, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.258391, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.246969, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.260826, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.279758, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.270953, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.255578, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.243596, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.263808, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291468, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.286109, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.272766, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.255041, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.234875, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.287649, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281349, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.265681, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.248189, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.238874, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281798, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.274501, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.256556, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.240197, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.244897, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278757, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.270362, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.252535, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.238459, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.246696, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.275414, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.266308, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.248185, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.236672, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.246715, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.339324, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.338327, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334602, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.328768, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.314355, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.338493, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.336895, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.332842, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.325585, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.309398, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.337134, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.334987, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.329198, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.320800, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302639, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.336533, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.333517, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.327077, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.317564, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298975, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.335400, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.332290, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.324899, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.315151, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296200, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.305230, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.304582, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302974, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299677, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291767, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.304783, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.304015, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301728, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298101, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288492, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.304009, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302936, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299877, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295172, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284047, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303678, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.302359, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298911, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.293569, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.281593, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.303059, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301634, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.297521, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291786, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.278826, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301928, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301050, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299392, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296207, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288021, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.301206, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.300231, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298269, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294403, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.284508, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.300647, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299324, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.296553, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.291684, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.280151, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299966, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298820, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.295356, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.289955, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.277689, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.299569, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.298108, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.294306, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.288283, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "Loss: 2.275615, Train accuracy: 0.183000, val accuracy: 0.230000\n",
      "best validation accuracy achieved: 0.350000\n",
      "best_params are (0.1, 0.001, 0.99, 128, 10, 128, 0.99)\n",
      "CPU times: user 12min 27s, sys: 52.8 s, total: 13min 20s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from itertools import product\n",
    "\n",
    "# Let's train the best one-hidden-layer network we can\n",
    "train_size = 1000\n",
    "val_size = 100\n",
    "train_X_, train_y_, val_X_, val_y_ = train_X[:train_size], train_y[:train_size], val_X[:val_size], val_y[:val_size]\n",
    "dataset = Dataset(train_X_, train_y_, val_X_, val_y_)\n",
    "\n",
    "\n",
    "learning_rates = [1e-1, 1e-2, 1e-3]\n",
    "reg_strengths = [1e-1, 1e-2, 1e-3]\n",
    "learning_rate_decays = [0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "hidden_layer_sizes = [128]\n",
    "num_epochs_list = [10]\n",
    "batch_sizes = [128]\n",
    "momentums = [0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "\n",
    "params_list = [learning_rates, reg_strengths, learning_rate_decays, hidden_layer_sizes,\n",
    "               num_epochs_list, batch_sizes, momentums]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "print(len(list(product(*params_list))))\n",
    "# find the best hyperparameters to train the network\n",
    "for params in product(*params_list):\n",
    "    learning_rate, reg_strength, learning_rate_decay, hidden_layer_size, num_epochs, batch_size, momentum = params\n",
    "    model = TwoLayerNet(n_input = train_X_.shape[1], n_output = 10,  hidden_layer_size=hidden_layer_size, \n",
    "                        reg=reg_strength)\n",
    "    \n",
    "    trainer = Trainer(model, dataset, MomentumSGD(momentum=momentum), num_epochs, \n",
    "                      batch_size, learning_rate, learning_rate_decay)\n",
    "    \n",
    "    loss_history, train_history, val_history = trainer.fit()\n",
    "    val_accuracy = val_history[-1]\n",
    "    \n",
    "    if val_accuracy >= best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_classifier = model\n",
    "        best_history = [loss_history, train_history, val_history]\n",
    "        best_params = params\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)\n",
    "print(f'best_params are {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x121a92590>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAGrCAYAAACBjHUSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5ieZZ33//d3+mQyM+l1MqmQUAJCQgKINEURXdEFFYm6uip2sWz12d3H37PlsT0oriCCXQOoAZUFESxUhZBCCZAE0jPJpJeZZJJMO39/3PdMJkMS0u8p79dx5Mhc13Xe1/2dEsgn5/c6z0gpIUmSJEnq+vJyXYAkSZIk6dAY4CRJkiSpmzDASZIkSVI3YYCTJEmSpG7CACdJkiRJ3YQBTpIkSZK6CQOcJEmSJHUTBjhJUo8XESsi4g25rkOSpKNlgJMkSZKkbsIAJ0nqtSLiIxGxJCK2RMQ9ETEiez4i4hsRsSEi6iJiQUScnr12RUS8GBH1EbEmIv4ut5+FJKk3McBJknqliLgU+L/Au4DhwErgzuzlNwIXAicDldkxm7PXvg98NKVUDpwO/OkEli1J6uUKcl2AJEk5MgP4QUppPkBE/DOwNSLGAE1AOTAJeCqltLDD65qAUyPi2ZTSVmDrCa1aktSrOQMnSeqtRpCZdQMgpbSDzCzbyJTSn4BvAzcBGyLi1oioyA69CrgCWBkRj0TEeSe4bklSL2aAkyT1VmuB0W0HEVEGDATWAKSUvpVSmgKcSqaV8u+z5+eklK4EhgC/Bn5xguuWJPViBjhJUm9RGBElbb+AO4APRsRrIqIY+C9gdkppRUScExHTI6IQ2AnsBlojoigiZkREZUqpCagDWnP2GUmSeh0DnCSpt/gtsKvDr4uBfwXuAmqB8cA12bEVwG1knm9bSaa18mvZa+8DVkREHfAxMs/SSZJ0QkRKKdc1SJIkSZIOgTNwkiRJktRNGOAkSZIkqZswwEmSJElSN2GAkyRJkqRuoiDXBXQ2aNCgNGbMmFyXIUmSJEk5MW/evE0ppcH7u3bEAS4iRgE/AYYCCbg1pXRjpzFXAv9OZo+cZuCzKaXHD3bfMWPGMHfu3CMtS5IkSZK6tYhYeaBrRzMD1wx8IaU0PyLKgXkR8fuU0osdxvwRuCellCLiDOAXwKSjeE9JkiRJ6rWO+Bm4lFJtSml+9uN6YCEwstOYHWnvRnNlZGbqJEmSJElH4JgsYhIRY4CzgNn7ufaOiFgE3Af87QFef11EzI2IuRs3bjwWJUmSJElSj3PUAS4i+gJ3kXm+ra7z9ZTSr1JKk4C3k3ke7hVSSremlKamlKYOHrzfZ/UkSZIkqdc7qgAXEYVkwtvMlNLdBxubUnoUGBcRg47mPSVJkiSptzqaVSgD+D6wMKV0wwHGTACWZhcxORsoBjYf6XvmyuotDXzzDy8zeWQFk6v6cerwCkqL8nNdliRJkqRe5mhWoXwt8D5gQUQ8kz33RaAaIKV0C3AV8P6IaAJ2Ae/usKhJt7Fm2y4eeWkDd82vASA/LzhpSF9OH1nJGVWVTB5ZySnDKygpNNRJkiRJOn6iq+WpqVOnpq64D1xKiXV1u3muZjvPr9ne/vvmnY1AJtSdPLQ8M0s3spLJVf2YNKzcUCdJkiTpsETEvJTS1P1dO5oZuF4lIhheWcrwylLedNowIBPq1m7fzYK2ULdmO39YuIFfzM3M1BW0h7pKJmdn6iYNL6e4wFAnSZIk6fA5A3eMpZRYs21X+yzdgjWZX9samgAozM+EujOqKjMtmCP7MXFYOUUFx2RHB0mSJEnd3MFm4AxwJ0BKiZqtu1jQofVywZrtbN+1N9RNGlaxzzN1Jw811EmSJEm9kQGuC0opsXpLNtSt2caC7Gxd/e5mAIry85g0PNt+mW3BPHloOYX5hjpJkiSpJzPAdRMpJVZubmhvu2x7tq5+TzbUFeRxyvAKJo+s4IyR/Th9ZCUnDe1rqJMkSZJ6EANcN9bamli5JRvqarbxXM12Xlhbx45sqCvOhrr2Z+qqKpkwuC8FhjpJkiSpWzLA9TCtrYnlm3fus1DKC2u2s7OxBYCSwjxOHb53O4PJIyuZMKQv+XmR48qlrmtPcwvbGprYsrORrTsb2drQRFNLKxWlBVSWFlJZWkhFSSEVpYVuDyJJko4rA1wv0NqaWLZpJwvWbGNBTR0L1mzjhbV1NGRDXWlhPqeOqGh/pu6MqkrGDTbUqWdqbG5lW0MjWxoa2bKzcZ9gtqWhw3GH622z2oeiuCCPimyoywS7DiGvw+8VJR3GZINg3+ICIvxzJ0mSDswA10u1tCaWbdyxz+qXL6ytY1dTJtT1KcrntBH7rn45dpChTl1LU0srWxsa2bpzb+jKHDeyZWfTvsfZcQcLY32LC+hfVsiAPkX0Lyuif5/MrwFlhZ2OiyjID+p2NVG3u5ntu5rYvqspc9z28e6mDueb288d7D+reUGn8Nch8HWY7at8RQDMBEXboyVJ6vkMcGrX0ppYunFHe6B7rmYbL9bWsbupFYCyonxOG5FZ9bLtubqxA8vIM9TpGGhqaWVbQ1P7zFdbq2LH4y0N2XPZ4/qDhLGyonz6l2XCViZ4ZULYPuGsrJAB2XP9+hQd9+05WlsT9Xua94a8AwS9/QXAul1NNLa0HvT+fYsLqCgp2Gemb9/AV0Bln1eGv0pbPyVJ6jYMcDqo5pZWlmzc0b6VwYI123lxbR17mjN/kexbXMBpbe2X2Zm6MYa6Xq+5pZWtDU2ZVsX2dsSmTrNh+wa0tm0y9qdPUX77zFcmhBXSb5/jDgGtrIh+fQopLuhZgSSlxO6m1n2C3faGgwfAjkGx7TnYAykqyNsb8vYb/vY/G1hRWkjfogL/zEuSdIIY4HTYmltaeXnD3lD33JrtLKytozEb6sqLCzhtZAVnZBdJmTyyktED+/hsTzfV3NLKtl1N7YFr3+fD9gazvceN1B1CGOtfVrg3lB2kVbFfH2eHjoWmltZXtHxu39V0yLOBh9L6ub/n+l55ft/nAytKC93uRJKkw2CA0zHR1NLKS+vr21e/fH7NdhbW1re3fFWUFHB6h43HJ4+spHqAoe5Ea2lNbGt7LuxAi3d0Ot6+q+mA9ystzN9n5qtj6DrQsWGs+2ltTexobN5nxq+uU8h7ZdtnE9sPsfWzrCifytJCxg4uY+LQCiYNL2fSsHJOGlJOaZE/L5IkdWSA03HT2JwJdW2tl89nZ+qaWjI/V5WlhZw+soLJI/u1L5RS1b/0hIe61tZEc2uipTXR3NpKS/bjln3Odzx34DF779Xa6TUdfm9ppSWxd0xLoiV1GteSaE1736u5JXuvlNpf0/Y+7ffqMKbja5qz79P2F+sD/bEuLshjYFlRp9bEV7Yqdgxj/uVaryalxJ7m1lfM+HUMedt3Zdptl27cweL19e3P3eYFjBlYxqTh5fsEu1H9+9iyKUnqtQxwOqHaQl1mj7ptLFizncXr6ttDXb8+hUweWcnwyhJaWtlvQGluzYablk6BqsO5V4aubNjZT6DqKvIC8vOC/LygIC8v+3uQl/09v8PvmV95+5x/5bg88vNov1e/PoX7LubRvpBHJpgZxtQVtLQmVm1pYFFtHYvW1bNoXR2L19WzcktD+z8+9CnK5+Sh5ZwyvJyJQ8uZNLyCScPK6denKLfFS5J0AhjglHN7mltYvK6+w+qX29m0Yw+F+XkdwkocJKwcyri8fcLP/oLOPoEoP8iL2Oc4Py+P/Ojwuvzs77HvmIK87GvzO9Sxz3HeK+rIj3BGQTqIhsZmXlq/Y59gt2hdPdsa9rb4Dq0oZtKwTJhrm7UbP6Ssxy1oI0nq3QxwkqRuKaXEhvo9mUBXm5mpW7iunqUbdrQ/d1eQF4wbXMakYRVMHJadtRtWwYjKEp/BlSR1SwcLcAUnuhhJkg5VRDC0ooShFSVcdPLg9vNNLa0s37STRevqWbyujkW19cxbuZV7nl3bPqa8pCAzU9ch2J08tJzyksJcfCqSJB0TBjhJUrdTmJ/HyUMzgYwzR7Sfr9vdxEvZWbq2YPfrp9fssyH8yH6l2Vm68vZ2zLGDyihwqwNJUjdggJMk9RgVJYVMHTOAqWMGtJ9LKbFm2y4Wr6vPPluXacd8aPFGWrKLHBUV5DFhcN/2VTDbgt3g8mLbMCVJXYoBTpLUo0UEVf37UNW/D68/ZWj7+T3NLSzZsGOfYPfnJZu4e/6a9jEDyoqyq2DuDXYnD3XvOklS7hjgJEm9UnFBPqeNqOS0EZX7nN+6s3Gf7Q0WrqvnzqdWs6upBYDI7l3XOdhVD3DvOknS8WeAkySpg/5lRZw3fiDnjR/Yfq61be+6DsFu0bp6HnhxXfvedaWF+Zw8tG/7oimZcFfBgDL3rpMkHTtuIyBJ0hHa1djCS+vrszN1e4Pdlp2N7WOGlBdnV8GsaJ+1mzCkr3vXSZIOyG0EJEk6DkqL8jlzVD/OHNWv/VxKiY079rCodt9g96O/rKCxObN3XX5eMG5Q2SuC3ch+pS6aIkk6KAOcJEnHUEQwpLyEIeUlXNhh77rmllZWbN6ZXQUzM1P3zOpt3PtcbfuY8uICJg7LbnEwPLMS5sRh5VS4d50kKcsWSkmScqh+dxMvra9vD3Zts3b1u/fdu64tzLXN2o0dVEahe9dJUo9kC6UkSV1UeUkhU0YPYMroffeuq92+m0Xr6vYJdo+8tJHmtr3r8vMYP6Qvp2QXTJk4rIJT3LtOkno8A5wkSV1MRDCiXykj+pVy6aS9e9c1NreydOOOfYLdX5Zu5u6n9927rm227pRhFUwaXs5JQ9y7TpJ6iiMOcBExCvgJMBRIwK0ppRs7jZkB/CMQQD3w8ZTSs0deriRJvVdRQR6nDK/glOEV+5x/tb3r8rJ717VtbdC2d11V/1L3rpOkbuZoZuCagS+klOZHRDkwLyJ+n1J6scOY5cBFKaWtEfFm4FZg+lG8pyRJ6uTge9fVsbA2E+5eWFvH/c/v3buurCh/nwVT2vawqyx10RRJ6qqO2SImEfEb4Nsppd8f4Hp/4PmU0siD3cdFTCRJOn527mluXzRl8bp6FtZm2jG372pqHzOyX2km2GXD3SnDyhk7qIwCF02RpBPiuC9iEhFjgLOA2QcZ9iHg/gO8/jrgOoDq6upjUZIkSdqPsuICzqruz1nV/dvPpZRYV7e7wxYHdSyqrefRToumTBjSl0nDM8/WTcwunjK4r4umSNKJdNQzcBHRF3gE+M+U0t0HGHMJcDNwQUpp88Hu5wycJEldwz6LpmT3rlu0ro71dXvaxwwsK8qsgjm0oj3cnTS0LyWFLpoiSUfquM3ARUQhcBcw8yDh7Qzge8CbXy28SZKkrmOfRVPO2nt+y87G9gVT2mbsbn9qJbubWoHsoimDyjKrYHZ4xq6qf6mzdZJ0lI5mFcoAvg8sTCndcIAx1cDdwPtSSi8d6XtJkqSuY0BZEeePH8T54we1n2tpTazcvLN9FcxFtXU8v3Y79y2obR/Tt7hg77N12WA3cVg5FSUumiJJh+qIWygj4gLgMWAB0Jo9/UWgGiCldEtEfA+4CliZvd58oKnANrZQSpLUc+xoWzSltp7F6+raw13d7ub2MSP7lWYDXWYlzFOGlzNmoIumSOq9DtZCecxWoTxWDHCSJPVsKSVqt+/OztbVtbdhLtu4c++iKQV5nDSkb3ugm5jd5mBweXGOq5ek4++4r0IpSZJ0qCKCEf1KGdGvlEsmDWk/v6e5haUbdmYWTVmXWTTlsZc3ctf8mvYxg/oWte9XN2lYOacMr2DCEBdNkdR7GOAkSVKXUFyQz6kjKjh1RMU+5zfv2JNZMCW7CuaidfX87MmV7Gneu2jK2EFl7XvWtQU8F02R1BMZ4CRJUpc2sG8x508o5vwJr1w0ZVH2mbqF6+pZULOd+57bu2hKeduiKdln6yYNy7RilrtoiqRuzGfgJElSj7FjT3N2tq4uu3BK5jm7+g6LplT1L20PdG3hbszAPi6aIqnL8Bk4SZLUK/QtLmDK6P5MGd2//VxKibXbd7Oodu+zdYtq63ho8QZaOiyacvLQvlx88hCumlLF2EFlufoUJOmgnIGTJEm90u6mFpZu3NG+CuaCNdt5avkWWhNMHd2fq6dU8ZYzhttyKemEcxsBSZKkQ7C+bje/enoNv5y7mqUbd1JSmMebTx/O1VOqOG/cQPLyXBRF0vFngJMkSToMKSWeWb2NWfNquOfZtdTvbmZEZQlXTaniqrOrGGOLpaTjyAAnSZJ0hHY3tfD7F9cza14Nj728kdYE54zJtFheMdkWS0nHngFOkiTpGFi3PdtiOW81yzq0WL5zShXn2mIp6RgxwEmSJB1DKSWezrZY/k+2xXJkv1KuOnskV02pYvRAWywlHTkDnCRJ0nGyu6mFBzu0WKYE08YMyLRYnjGcvsXu2iTp8BjgJEmSToDa7bv41dNrmDW3hmWbdlJamM+bTx/G1VOrOHesLZaSDo0BTpIk6QRKKTF/VabF8t5n11K/J9tiOaWKq8+uonpgn1yXKKkLM8BJkiTlyO6mFh54YR2z5tXw+JJNmRbLsQPaV7G0xVJSZwY4SZKkLmDttmyL5bwalm/aSZ+i/PaNwqePHWCLpSTAACdJktSlZFost2ZXsaxlx55mqvqXctXZVVw9pYpRA2yxlHozA5wkSVIXtauxhQdf3LfFcnqHFssyWyylXscAJ0mS1A2s2baLX82vYda8GlZsbqBPUT5XTM60WE4bY4ul1FsY4CRJkrqRlBLzVmZaLO99LtNiOWpApsXyqrNtsZR6OgOcJElSN7WrsYXfvVDLrHk1/GXpZlKC88YN5OopVbx58jD6FNliKfU0BjhJkqQeoGZrA7+av4ZZ82tYubmBso4tlmMHEGGLpdQTGOAkSZJ6kJQSc1duZdbcGu59bi07G1uoHtAn02I5ZSRV/W2xlLozA5wkSVIP1dDYzO+eX9feYglw/vhMi+Xlp9tiKXVHBjhJkqReoGZrA3fPz2wUvmpLpsXyLWcM5+opozhnTH9bLKVuwgAnSZLUi6SUmLNiK7+cu5r7FtTS0NjC6IF9uPrsKv56ShUj+5XmukRJB2GAkyRJ6qV27tnbYvnEss1EdGixPG04pUX5uS5RUicGOEmSJLF6S7bFcv5qVm/ZRd/iAt4yeThXT61i6mhbLKWuwgAnSZKkdq2tiadWbGHWvBp+m22xHDOwD1dPqeIdZ9tiKeWaAU6SJEn7tXNPM/c/v45Z81bz5LItRMBrxw/i6ilVvOm0YbZYSjlwXAJcRIwCfgIMBRJwa0rpxk5jJgE/BM4G/ldK6euvdl8DnCRJUm6s3tLAXfNrmDWvhpqtmRbLt56R2Sh8ii2W0glzvALccGB4Sml+RJQD84C3p5Re7DBmCDAaeDuw1QAnSZLU9bW2JmYv39tiuauphbGDyjItlmeNZIQtltJxdUJaKCPiN8C3U0q/38+1LwE7DHCSJEndy449zdy/oJZZ82qYvTzTYnnBhEyL5RtPtcVSOh6Oe4CLiDHAo8DpKaW6/Vz/EgcJcBFxHXAdQHV19ZSVK1cedU2SJEk6tlZtbmDW/BrumlfDmm27KC8u4K1nZlosz662xVI6Vo5rgIuIvsAjwH+mlO4+wJgv4QycJElSj9Damnhy+WZmzavh/gXr2NXUwrhBZVw1pYq/PnskwyttsZSOxnELcBFRCNwLPJBSuuEg476EAU6SJKnH2bGnmd9mWyyf6tRi+abThlFSaIuldLgOFuAKjuKmAXwfWHiw8CZJkqSeq29xAe+aOop3TR3Fys07uWteDXfNX8P1dz5DeUkBV51dxYzp1Zw0tDzXpUo9wtGsQnkB8BiwAGjNnv4iUA2QUrolIoYBc4GK7JgdwKn7e06ujTNwkiRJ3Vtra+LJZZu5c85qfvf8OhpbWpk2ZgAzzq3m8tOHUVzgrJx0MG7kLUmSpJzYvGMPs+bVcPtTq1i5uYEBZUW8c0oV75lWzZhBZbkuT+qSDHCSJEnKqdbWxJ+XbmLmk6v4/cL1tLQmXnfSIK6dVs0bTh1KYX5erkuUugwDnCRJkrqM9XW7+fmc1dz51CrWbt/N4PJirjlnFNdMq2akm4RLBjhJkiR1PS2tiYcXb2Dm7FU8tHgDAVwycQgzzq3mopOHkJ/nvnLqnQxwkiRJ6tJqtjZw51OruXPOajbt2MPIfqVcc84o3n3OKIZUlOS6POmEMsBJkiSpW2hqaeX3L67n9tmreHzJJgrygstOHcqM6aM5f/xA8pyVUy9wXPaBkyRJko61wvw8rpg8nCsmD2f5pp3c8dQqfjl3Nfc/v44xA/vwnmnVXD2lioF9i3NdqpQTzsBJkiSpS9vd1MLvnl/HzNkrmbNiK0X5ebx58jBmTB/NOWP6E+GsnHoWWyglSZLUI7y0vp7bZ6/irnk11O9p5qQhfZkxvZp3nF1FZWlhrsuTjgkDnCRJknqUhsZm7n22lpmzV/JszXZKCvP4qzNGMOPc0ZxZVemsnLo1A5wkSZJ6rAU127n9qZX85pm1NDS2cNqICmZMH82VrxlBWbFLPqj7McBJkiSpx6vf3cSvn1nLzCdXsmhdPX2LC3j7WSO4dtpoTh1RkevypENmgJMkSVKvkVJi/qptzJy9knufq6WxuZWzqvsxY/po3nrGcEoK83NdonRQBjhJkiT1StsaGpk1r4bbZ69i2aadVJYWctXZVVw7vZoJQ/rmujxpvwxwkiRJ6tVSSjy5bAszZ6/kgRfW0dSSOHfcAGZMH82bThtGUUFerkuU2rmRtyRJknq1iOC88QM5b/xANtbv4ZfzVnP77FV8+o6nGVhWxDunjuLaadVUD+yT61Klg3IGTpIkSb1Sa2visSWbmPnkSv6wcD2tCS48eTAzplfz+klDKMh3Vk65YQulJEmSdBC123fx8zmrufOp1ayr283QimKuOaeaa6aNYnhlaa7LUy9jgJMkSZIOQXNLK39atIGZs1fx6MsbCeDSSUOZcW41F540mPw8NwjX8eczcJIkSdIhKMjP442nDeONpw1j9ZYG7nhqFb+Yu5o/LFxPVf9S3jOtmndNHcXg8uJcl6peyhk4SZIk6SAam1t58MV1zHxyFU8s20xBXvCm04YxY3o1540fSISzcjq2nIGTJEmSjlBRQR5vPWMEbz1jBEs27OCOp1Yxa14N9y2oZdygMq6dXs1VZ1fRv6wo16WqF3AGTpIkSTpMu5ta+O2CWmbOXsW8lVszIW/ycK6dXs2U0f2dldNRcRETSZIk6ThZWFvH7bNX8aun17BjTzMTh5Yz49xq3n7WSCpKCnNdnrohA5wkSZJ0nO3c08w9z65l5uyVPL+mjtLCfK58zQhmTB/N5KrKXJenbsQAJ0mSJJ1Az9VsY+aTq/jNs2vY3dTKGVWVXDutmre9ZgR9ilyGQgdngJMkSZJyYPuuJn799Bpmzl7JS+t3UF5cwDvOHsm106uZNKwi1+WpizLASZIkSTmUUmLuyq3cPnsV9z1XS2NLK1NH92fGudW8+fThlBTm57pEdSEGOEmSJKmL2LKzkbvm1TBz9kpWbG6gX59Crj67imunVzNucN9cl6cuwAAnSZIkdTGtrYknlm1m5uyVPPjCeppbE+ePH8iM6aO57NShFBXk5bpE5chxCXARMQr4CTAUSMCtKaUbO40J4EbgCqAB+EBKaf7B7muAkyRJUm+zoX43v5xbw+2zV7Fm2y4G9S3m3edUcc051Ywa0CfX5ekEO14BbjgwPKU0PyLKgXnA21NKL3YYcwXwaTIBbjpwY0pp+sHua4CTJElSb9XSmnj0pY3MnL2SPy3aQAIuOnkwM6aP5pKJgynId1auNzhYgDviNUxTSrVAbfbj+ohYCIwEXuww7ErgJymTEp+MiH4RMTz7WkmSJEkd5OcFl0wawiWThrB22y7unLOaO59axUd+MpfhlSV86IKxvO+80RQXuOhJb3VMInxEjAHOAmZ3ujQSWN3huCZ7rvPrr4uIuRExd+PGjceiJEmSJKlbG9GvlM9fdjJ//qdLueW9UxgzsIz/uG8hr/9/j/CbZ9bQ2tq11rLQiXHUAS4i+gJ3AZ9NKdUdyT1SSremlKamlKYOHjz4aEuSJEmSeozC/DwuP30Yd1x3Lj/90DQqSgq5/s5nuPKmP/OXpZtyXZ5OsKMKcBFRSCa8zUwp3b2fIWuAUR2Oq7LnJEmSJB2m1500mHs/fQE3vOtMNu/Yw7W3zeZvfzSHl9bX57o0nSBHHOCyK0x+H1iYUrrhAMPuAd4fGecC233+TZIkSTpyeXnBX59dxZ/+7mL++c2TmLNiC5d/81H+cdZzrNu+O9fl6Tg7mlUoLwAeAxYArdnTXwSqAVJKt2RD3reBy8lsI/DBlNJBl5h0FUpJkiTp0G3d2ci3H1rCT55YQX5e8OELxvHRi8ZRXlKY69J0hNzIW5IkSerhVm9p4GsPLOaeZ9cysKyI699wEu+ZVk2hWw90OwcLcH43JUmSpB5g1IA+fOs9Z/GbT76WCUP68m+/eYE3fuNRfvd8LV1t0kZHzgAnSZIk9SBnjurHndedyw8+MJWCvOBjP5vPVd/5C3NXbMl1aToGDHCSJElSDxMRXDppKPdf/zq+ctVkarbu4upbnuCjP53L0o07cl2ejoLPwEmSJEk9XENjM99/bDm3PLKU3c2tXDutms+8/iQGlxfnujTth4uYSJIkSWLTjj18648vc/vsVRQX5PHRi8bz4deNpU9RQa5LUwcGOEmSJEntlm3cwVd/t5jfvbCOIeXFfP6yk7l6ShUFrljZJbgKpSRJkqR24wb35Zb3TeGuj59HVf9S/unuBbz5xsf448L1rljZxRngJEmSpF5qyugB3PXx87nlvWfT3Jr40I/n8p7bnuS5mm25Lk0HYICTJEmSerGI4PLTh/Pg5y7k3688jZfX7+Bt3/4zn77jaVZvach1eerEZ+AkSZIktavf3cStjy7jtseW0dKaeP95Y/jUJRPoX1aU69J6DRcxkSRJknRY1tft5hu/f4lfzF1NWXEBn7xkAh84fwwlhfm5Lq3HcxETSZIkSYdlaEUJX77qDO6//kLOGTOAL9+/iEu//jB3z6+htVYCNpAAACAASURBVLVrTQL1JgY4SZIkSQc0cVg5P/jAOdz+kekM7FvM53/xLG/978d57OWNuS6tVzLASZIkSXpV548fxG8++Vq+9Z6zqNvdxPu+/xTv/8FTvLi2Ltel9SoGOEmSJEmHJC8veNuZI/jjFy7iX95yCs+u3sZb/vsxvvCLZ1m7bVeuy+sVXMREkiRJ0hHZ3tDEzY8s4Yd/XkEAH3ztWD5xyXgqSgpzXVq35iqUkiRJko6bmq0N3PDgS/zqmTX0Ky3k05eexHvPHU1RgQ1/R8JVKCVJkiQdN1X9+3DDu1/D/3zqAk4bUcn/ufdF3nDDI9z73Fq62oRRd2eAkyRJknRMnD6ykp9+aBo//ttp9CnK51O3P83bb/4Ls5dtznVpPYYBTpIkSdIxExFcdPJg7vvM6/j6O89kQ91u3n3rk3z4x3NYsqE+1+V1ewY4SZIkScdcfl5w9ZQqHvq7i/mHyycye9kW3viNR/nnuxewoW53rsvrtlzERJIkSdJxt2VnI//9p5f52ZMrKczP4yOvG8d1F46jrLgg16V1Oa5CKUmSJKlLWLl5J199YDH3PVfLoL7FfPYNJ3HNOaMoyLc5sI2rUEqSJEnqEkYPLOOma8/mV584n3GDyviXXz/PG7/5KA++sM4VKw+BAU6SJEnSCXdWdX9+/tFzue39Uwngup/O413ffYL5q7bmurQuzQAnSZIkKScigstOHcoDn72Q/3rHZJZvauCvb/4Ln5g5jxWbdua6vC7JZ+AkSZIkdQk79zTzvceW891Hl9LY3Mp7zx3Npy+dwMC+xbku7YRyERNJkiRJ3caG+t3c+IeXuXPOavoU5vOxi8fzt68dS2lRfq5LOyFcxESSJElStzGkvIT/fMdkHvjshZw7fiBfe2Axl3z9YX4xdzUtrV1rAupEO6oAFxE/iIgNEfH8Aa73j4hfRcRzEfFURJx+NO8nSZIkqfeYMKQvt71/Kr/46HkMqyzhH2Y9x1u+9RgPL97Qa1esPNoZuB8Blx/k+heBZ1JKZwDvB248yveTJEmS1MtMGzuAX33ifG6ecTa7mlr4wA/n8N7vz+b5NdtzXdoJd1QBLqX0KLDlIENOBf6UHbsIGBMRQ4/mPSVJkiT1PhHBFZOH8/vPXcSX/upUFtbW89b/fpzP3vk0NVsbcl3eCXO8n4F7FvhrgIiYBowGqjoPiojrImJuRMzduHHjcS5JkiRJUndVVJDHB147lof//mI+ecl47n9+HZd+/RH+67cL2d7QlOvyjrujXoUyIsYA96aUXvF8W0RUkGmbPAtYAEwCPpJSeuZA93MVSkmSJEmHqnb7Lm548CVmza+hoqSQT10ygfefP5rigu67YuVx3UbgYAGu07gAlgNnpJTqDjTOACdJkiTpcC2sreMrv1vEw4s3UtW/lL9/00T+6owR5OVFrks7bDnbRiAi+kVEUfbww8CjBwtvkiRJknQkThlewY8+OI2ZH55OZWkh19/5DFfe9Gf+snRTrks7po5qBi4i7gAuBgYB64H/DRQCpJRuiYjzgB8DCXgB+FBKaevB7ukMnCRJkqSj0dqauOfZtXztgcWs2baLSyYO5p/efAoTh5XnurRDclxbKI81A5wkSZKkY2F3Uws/fWIl//2nl9mxp5mrp1Tx+csmMqyyJNelHZQBTpIkSVKvta2hkZseWsKP/7KSvDz48AXj+OhF4ygvKcx1aftlgJMkSZLU663e0sDXH1zMb55Zy4CyIq5//UlcO72awvzjvbva4cnZIiaSJEmS1FWMGtCHG685i//51AVMHFrO/77nBRavq891WYelINcFSJIkSdKJNLmqkts/Mp0Xa+s4bURlrss5LM7ASZIkSep1IqLbhTcwwEmSJElSt2GAkyRJkqRuwgAnSZIkSd2EAU6SJEmSugkDnCRJkiR1E11uI++I2AiszHUd+zEI2JTrIqRX4c+pujp/RtXV+TOqrs6f0d5hdEpp8P4udLkA11VFxNwD7YYudRX+nKqr82dUXZ0/o+rq/BmVLZSSJEmS1E0Y4CRJkiSpmzDAHbpbc12AdAj8OVVX58+oujp/RtXV+TPay/kMnCRJkiR1E87ASZIkSVI3YYCTJEmSpG7CAHcIIuLyiFgcEUsi4p9yXY/UUUSMioiHIuLFiHghIq7PdU3S/kREfkQ8HRH35roWqbOI6BcRsyJiUUQsjIjzcl2T1FFEfC77//nnI+KOiCjJdU3KDQPcq4iIfOAm4M3AqcB7IuLU3FYl7aMZ+EJK6VTgXOCT/oyqi7oeWJjrIqQDuBH4XUppEnAm/qyqC4mIkcBngKkppdOBfOCa3FalXDHAvbppwJKU0rKUUiNwJ3BljmuS2qWUalNK87Mf15P5S8fI3FYl7SsiqoC3AN/LdS1SZxFRCVwIfB8gpdSYUtqW26qkVygASiOiAOgDrM1xPcoRA9yrGwms7nBcg385VhcVEWOAs4DZua1EeoVvAv8AtOa6EGk/xgIbgR9m23y/FxFluS5KapNSWgN8HVgF1ALbU0oP5rYq5YoBTuohIqIvcBfw2ZRSXa7rkdpExFuBDSmlebmuRTqAAuBs4DsppbOAnYDPvKvLiIj+ZDrAxgIjgLKIeG9uq1KuGOBe3RpgVIfjquw5qcuIiEIy4W1mSunuXNcjdfJa4G0RsYJMG/qlEfGz3JYk7aMGqEkptXUvzCIT6KSu4g3A8pTSxpRSE3A3cH6Oa1KOGOBe3RzgpIgYGxFFZB4YvSfHNUntIiLIPLexMKV0Q67rkTpLKf1zSqkqpTSGzH9D/5RS8l+O1WWklNYBqyNiYvbU64EXc1iS1Nkq4NyI6JP9//7rcaGdXqsg1wV0dSml5oj4FPAAmRV/fpBSeiHHZUkdvRZ4H7AgIp7JnvtiSum3OaxJkrqbTwMzs/9Yuwz4YI7rkdqllGZHxCxgPpnVp58Gbs1tVcqVSCnlugZJkiRJ0iGwhVKSJEmSugkDnCRJkiR1EwY4SZIkSeomDHCSpMMWEfkRsSMiqk/w+344Ih4+lBo6jj3C93owImYc6eslSToeDHCS1Atkg07br9aI2NXh+LBDSkqpJaXUN6W06jBqeF1EPHq473UsaziQiPiPiPhRp/u/MaU082jvLUnSseQ2ApLUC6SU+rZ9nN1Q+8MppT8caHxEFKSUmo9xGW8B3N4ix47T91aSdII4AydJapuB+nlE3BER9cB7I+K8iHgyIrZFRG1EfCsiCrPjCyIiRcSY7PHPstfvj4j6iHgiIsZ2epsrgN9GxG0R8eVO739fRHwm+/G/RMSy7H1eiIi3HaDmzjUMjoh7I6IuIp4ExnYa/+2IqMlenxMR52fPvxX4B2BGdkZyXvb84xHxgezHeRHxbxGxMiI2RMSPIqIie21Cto73Z++/MSL+6SBf67dFxDPZOlZFxL92un5h9uu+PSJWR8T7suf7RMQ3sq/ZHhGPRkRxRLwhG8o73qMmIi4+ku9t9jWTI+IPEbElItZFxD9ExMiIaIiIfh3GTcte9x+EJekEMcBJktq8A7gdqAR+Tmaz2OuBQWQ2jL8c+OhBXn8t8K/AAGAV8O9tFyJiFNAvpfQccAdwTURE9tpA4NLsewK8lH2/SuA/gdsjYugh1P8doB4YBlwH/G2n67OBM7L1zQJ+GRHFKaV7ga8CM7MtmVP2c+8PA+8FLgbGA/2BGzuNOR+YALwJ+P8i4qQD1LkDmAH0A/4KuD4bIsmG3t8CNwADgbOABdnXfSNb//Ts5/BFoPXAX459HPL3NiIqgT8A/wMMB04GHk4prQEeB97Z4b7vA+5wRk+SThwDnCSpzeMppf9JKbWmlHallOaklGanlJpTSsuAW4GLDvL6WSmluSmlJmAm8JoO164A7s9+/DBQCJyXPX4X8FhKaT1ASukXKaXabB23AyuAqQcrPDt79HbgX1NKDdmg+NOOY1JKP00pbcmGja8CFWQC16GYAXw9pbQ8pVRPJjxdGxEd/z/6pZTS7pTSfOAF4Mz93Sil9KeU0gvZz+9Z4E72fl3fC9yf/Ro0p5Q2pZSeiYh84APAZ7Jfm5aU0uPZr/WhOJzv7duAVSmlG1NKe1JKdSmlp7LXfpytkeys2zV0+jpLko4vA5wkqc3qjgcRMSnb2rguIuqA/0NmxuZA1nX4uAHo2+H4CrLPv6WUWsnMAr0ne+1aMoGv7X0/EBHPZtv7tgGTXuV9AYYC+Z0+h5WdPp9/iIhFEbEd2AqUHcJ924zodL+VQBEwuO1ESulgn3/HOs6LiIezrZbbyczutdUxCli6n5cNzb7f/q4disP53h6oBoBfAWdGZuXPy4EN2cAqSTpBDHCSpDap0/F3geeBCSmlCuDfgDjcm0ZEEXABmba8NncA78y2DJ4N3J0dO45MK+THgYEppX7AokN43/Vk2glHdTjXvr1ARFwCfB64ikzrYn8yrYxt9+38uXe2Fhjd6d6NwMZXed3+3AncBYxKKVUC3+tQx2oyLZqdrc++3/6u7QT6tB1kZ8YGdhpzON/bA9VASqkhW/sMMu2Tzr5J0glmgJMkHUg5sB3YGRGncPDn3w7mImBeSmln24mU0hygjkzr3m+zbYmQmbVKZIJRRMRHyMzAHVS2lfDXZJ49K42I08kEjI6fSzOwiUz75pfIzMC1WQ+MaXsubz/uAD4fEWMiopzMs3l3ZGcTD1c5sCWltDsiziXThtjmZ8DlEXFVdpGWQRFxZkqpBfgR8M2IGBaZPfBem20dXQSUR8Sbssf/O/s5vloNB/re3gNUR8SnsoukVETEtA7Xf0Lm+cK3ZOuVJJ1ABjhJ0oF8AfgbMguDfJe9i4wcrgNtH3AH8AYyi2sAkH127b+Bp4BaYCKZxUcOxcfJzKytB74P/LDDtd+SmQF8mcwzdXXZ+7f5OZkWxS0R8RSvdFt2zGPAMjJfk+sPsa791fl/sytCfhH4RduFlNJyMgub/COwBZgPTM5e/hywEJiXvfZfQKSUtgKfJvN82prstY7tnPtzwO9tSmk7cBmZ2cr1ZBaV6fjs46NktiGanVKqObxPXZJ0tCKlV+sakSTpyEXES8BbU0ov5boWHRuR2ZD9BymlH+W6FknqbZyBkyQdNxFRAnzf8NZzZNs+Twd+metaJKk3cgZOkiQdkoiYSaYl9tMpJRcwkaQcMMBJkiRJUjdhC6UkSZIkdRMFuS6gs0GDBqUxY8bkugxJkiRJyol58+ZtSikN3t+1LhfgxowZw9y5c3NdhiRJkiTlRESsPNA1WyglSZIkqZswwEmSJElSN2GAkyRJkqRuwgAnSZIkSd2EAU6SJElSr7Rm265cl3DYDHCSJEmSepW5K7bwtz+aw+u+8ieWbdyR63IOS5fbRkCSJEmSjrWUEo++vImbHlrCU8u3MKCsiM9fdjID+xbnurTDYoCTJEmS1GO1tCYeeGEdNz+8hOfX1DGsooR/e+upXDNtFH2Kul8c6n4VS5IkSdKraGpp5ddPr+E7jyxl2cadjB1Uxleumsw7zqqiqKD7PklmgJMkSZLUY+xqbOHnc1Zx22PLWbNtF6cMr+Db157Fm08fTn5e5Lq8o2aAkyRJktTt1e1u4qdPrOQHjy9n885Gpo7uz3+8/XQunjiYiO4f3NoY4CRJkiR1W5t27OGHf17OT/6ykvo9zVx08mA+eckEpo0dkOvSjgsDnCRJkqRuZ822Xdz26DLunLOKPc2tXHH6cD5+8XhOH1mZ69KOKwOcJEmSpG5j6cYd3PLwUn719BoA3nHWSD528XjGD+6b48pODAOcJEmSpC7v+TXb+c7DS/nt87UUF+Tx3nNH85ELxzGyX2muSzuhDHCSJEmSuqynlm/hpoeW8MhLGykvLuATF4/ng68dy6ButgH3sWKAkyRJktSlpJR4+KWN3PzQEuas2MrAsiL+/k0Ted95o6koKcx1eTllgJMkSZLUJbS0Ju5/vpabH1rKi7V1jKgs4Ut/dSrvPqea0qL8XJfXJRjgJEmSJOVUY3Mrv356Dd95ZCnLN+1k3OAyvnb1GVz5mpEUFeTlurwuxQAnSZIkKScaGpu586nV3PbYMmq37+a0ERXcPONs3nTaMPLzes7m28eSAU6SJEnSCbV9VxM/fWIFP/jzCrbsbGTa2AF8+aozuPCkQUQY3A7GACdJkiTphNhYv4cf/Hk5P31iJTv2NHPppCF84uLxTB0zINeldRsGOEmSJEnHVc3WBm59dBk/n7OaxpZW3jJ5OB+/eDynjajMdWndjgFOkiRJ0nGxZEM933l4Gb95Zg0R8NdnVfHRi8YxbnDfXJfWbRngJEmSJB1Tz9Vs4+aHlvLAi+soLsjj/eeN4SMXjmV4ZWmuS+v2DinARcTlwI1APvC9lNKXDzDuKmAWcE5KaW723D8DHwJagM+klB44FoVLkiRJ6jpSSsxevoWbHlrCYy9vorykgE9dMoEPnD+GgX2Lc11ej/GqAS4i8oGbgMuAGmBORNyTUnqx07hy4HpgdodzpwLXAKcBI4A/RMTJKaWWY/cpSJIkScqVlBJ/WrSBmx5awvxV2xjUt5h/vHwS7z23mvKSwlyX1+McygzcNGBJSmkZQETcCVwJvNhp3L8DXwH+vsO5K4E7U0p7gOURsSR7vyeOtnBJkiRJudPSmrhvQS03P7SERevqGdmvlH+/8jTeOXUUJYX5uS6vxzqUADcSWN3huAaY3nFARJwNjEop3RcRf9/ptU92eu3Izm8QEdcB1wFUV1cfWuWSJEmSTrg9zS3cPX8N331kKSs2NzB+cBn/751n8rbXjKAwPy/X5fV4R72ISUTkATcAHzjSe6SUbgVuBZg6dWo62pokSZIkHVsNjc3cPnsVtz22jPV1e5g8spJb3juFN546lLw8N98+UQ4lwK0BRnU4rsqea1MOnA48nN01fRhwT0S87RBeK0mSJKkL297QxI+fWMEP/7ycrQ1NnDtuAF9/55lcMGEQ2b//6wQ6lAA3BzgpIsaSCV/XANe2XUwpbQcGtR1HxMPA36WU5kbELuD2iLiBzCImJwFPHbvyJUmSJB0PG+p28/3Hl/OzJ1eys7GFN5wyhI9fPIEpo/vnurRe7VUDXEqpOSI+BTxAZhuBH6SUXoiI/wPMTSndc5DXvhARvyCz4Ekz8ElXoJQkSZK6rtVbGvjuo0v5xdwamltaeesZI/j4xeM5ZXhFrksTECl1rUfOpk6dmubOnZvrMiRJkqRe5eX19Xzn4aX85tm15Edw1ZQqPnrhOMYMKst1ab1ORMxLKU3d37WjXsREkiRJUvf17Opt3PTQEh58cT2lhfl88PwxfPh14xhWWZLr0rQfBjhJkiSpl0kp8cSyzdz80FIeX7KJytJCPvP6k/jg+WPoX1aU6/J0EAY4SZIkqZdobU38cdEGbn54CU+v2sbg8mK+eMUkrp0+mr7FRoPuwO+SJEmS1MM1t7Ry34Jabn5oKYvX11PVv5T/ePvpXD2lipLC/FyXp8NggJMkSZJ6qN1NLdw1v4bvPrKMVVsaOHloX7757tfw1jOGU5Cfl+vydAQMcJIkSVIPs3NPM7fPXsVtjy1jQ/0ezhzVj395yym84ZSh5OW5+XZ3ZoCTJEmSeoitOxv50V9W8KO/rGD7riZeO2Eg33j3azh//EAiDG49gQFOkiRJ6ubW1+3me48tY+bsVTQ0tnDZqUP5xMXjOau6f65L0zFmgJMkSZK6qVWbG7jl0aXMmltDS0q87cwRfOyi8UwcVp7r0nScGOAkSZKkbmbRujq+8/BS/ufZtRTk5fHOqVV89MLxVA/sk+vSdJwZ4CRJkqRuYv6qrdz80FL+sHA9ZUX5fPh14/jwBWMZUlGS69J0ghjgJEmSpC7uuZptfPV3i3l8ySb69Snkc284mb85fzT9+hTlujSdYAY4SZIkqYtasWknX3twMfc9V8uAsiL+1xWncO30asqK/Wt8b+V3XpIkSepiNu3Yw7f++DK3z15FYX4en7l0Ah+5cBzlJYW5Lk05ZoCTJEmSuoide5q57bFl3PboMnY3t/KeaaP4zOtPYki5z7gpwwAnSZIk5VhTSyt3PrWKG//4Mpt2NHLF5GH83RsnMm5w31yXpi7GACdJkiTlSEqJ3y5Yx9ceWMSKzQ1MGzuA294/yQ24dUAGOEmSJCkHnli6mS/fv5Bna7YzcWg5P/zAOVw8cTARkevS1IUZ4CRJkqQTaGFtHV/53SIeXryREZUlfP2dZ/KOs0aSn2dw06szwEmSJEknQM3WBm74/Uv86uk1VJQU8sUrJvH+88ZQUpif69LUjRjgJEmSpONo685Gbn54CT/+y0oIuO7CcXzioglU9nFLAB0+A5wkSZJ0HOxuauGHf17BzQ8vYeeeZq46u4rPXXYyI/qV5ro0dWOHFOAi4nLgRiAf+F5K6cudrn8M+CTQAuwArkspvRgRY4CFwOLs0CdTSh87NqVLkiRJXU9zSyt3za/hG79/mXV1u3n9pCH8w+WTmDisPNelqQd41QAXEfnATcBlQA0wJyLuSSm92GHY7SmlW7Lj3wbcAFyevbY0pfSaY1u2JEmS1LWklPjDwg189XeLeHnDDs6q7seN17yG6eMG5ro0HUhdLVQMz3UVh+VQZuCmAUtSSssAIuJO4EqgPcCllOo6jC8D0rEsUpIkSerK5q3cwpfvX8ScFVsZN6iMW957Nm86bZhbAnRV61+ER74Mi+6DTz4FA8fnuqJDdigBbiSwusNxDTC986CI+CTweaAIuLTDpbER8TRQB/xLSumx/bz2OuA6gOrq6kMuXpIkScqlJRt28NXfLeLBF9czuLyY/3zH6bxr6igK8/NyXZr2Z8OiTHB74ddQVAYXfA76DMh1VYflmC1iklK6CbgpIq4F/gX4G6AWqE4pbY6IKcCvI+K0TjN2pJRuBW4FmDp1qrN3kiRJ6tLW1+3mm394iZ/PWU2fogK+cNnJfOh1Y+lT5BqBXdLGl+CRr8Dzd0Fhn0xwO//T3S68waEFuDXAqA7HVdlzB3In8B2AlNIeYE/243kRsRQ4GZh7RNVKkiRJOVS3u4nvPrKU7z++nJbWxN+cP4ZPXTKBgX2Lc12a9mfTkmxwmwUFpfDa6+H8z0BZ930u8VAC3BzgpIgYSya4XQNc23FARJyUUno5e/gW4OXs+cHAlpRSS0SMA04Clh2r4iVJkqQTYU9zCz97chXf/tPLbG1o4srXjOALl02kemCfXJem/dm8FB79Gjz3cygogfM+lQlvZYNyXdlRe9UAl1JqjohP8f+3d+fRcdb3vcffvxmt1r6MZVubZW3eAGPLxtjIMruTsiTNAqE0C2lom9A2TZM0Xe655+T23NLAJSEJTUOAdCPhtmluD+0pYUkCNovBMoaCsS3J8iav2vdllt/94xlpRrJsCyzNM2N9XufoSPPM81hfwyDmo9/v+X7hWZwxAk9Ya/caY74JNFprnwbuM8bcAPiBbpztkwBbgG8aY/xACPg9a23XXPxFRERERERmWyhkefrtEzz43AHauoepry7kT7ctZ3VxjtulyXS6DjnB7e2nwJsCG7/oBLfMhW5XNmuMtfF1y1ldXZ1tbNQOSxERERFxj7WW7c0d3P/Mfvad7GPVkmy+8aHl1Ff73C5NptN92Alub/0UvMlQdw9s/jJkFbld2QdijNltra2b7jndZSkiIiIiEuWdtl7u/8U+XmnppDQ/nYfvXMOtly/B49FIgLjTcxS2PwhvPQnGCxu+4DQoyVrkdmVzRgFORERERAQ40jnIg8818R9vnyA/I4X/eetK7rqqjNQkr9ulyVQ9x2DH/4E9/wzGwLrPQf1XIHuJ25XNOQU4EREREZnXOgZG+f6vWnjy9SMkeTz8wXVV3LtlGVlpyW6XJlP1HneC25v/6Dxe+2knuOWUuFtXDCnAiYiIiMi8NDga4LEdh3h0+0FGAiHuWF/Kl6+vZmF2mtulyVR9J+Hlh2D334MNwZW/DfV/ArmlF7z0UqMAJyIiIiLzij8Y4qldx3j4hWY6BkbZtmoRX9tWS6Uv0+3SZKr+U/Dyt6Hxx2CDsOYuqP8q5JW7XZlrFOBEREREZF6w1vLMu6d44NkDHOoYZMPSfB799DrWluW5XZpM1X8aXvkOND4BQT+s+RRs+RrkLXW7MtcpwImIiIjIJW9nayd//cx+3j7WQ01RJo9/po7rli/EGHWWjCsD7U5w2/U4BMfgijthy1chf5nblcUNBTgRERERuWTtP9XH3zyzn18faGdxThrf+vjlfGxtCV6NBIgvgx3wysOw6zEIjMDldzgrbgWVblcWdxTgREREROSSc7xnmIeea+Lne9rISk3iGx9azmc3LSUtWSMB4spgJ7z6XXjjR+Afgss+AQ1fh8JqtyuLWwpwIiIiInLJ6Bka429fPMjfv3oYgHvrl/H7WyvJXZDibmEy2VAXvPZ9eP2HMDYIqz8GDX8Kvhq3K4t7CnAiIiIikvBG/EH+/tXD/O2vW+gfDfCxtSX88Y01FOemu12aRBvuhtcegZ1/B2MDsOoj0PANWLjc7coShgKciIiIiCSsYMjyb7vbeOj5Jk71jXDd8oV8fVstyxdlu12aRBvugZ0/gJ1/C6N9sPJ2J7gVrXS7soSjACciIiIiCcdayy/3neFbz+6n6fQAV5Tm8p0717BxWYHbpUm0kV5nte21R2C0F1bc6gS3RavdrixhKcCJiIiISELZfaSbv3lmP28c7qKiMIMf/NZatq1epJEA8WSkz7m/7bXvw0gP1P4GbP0GLL7c7coSngKciIiIiCSEg+0DPPCLA/xi7ykKM1P5q4+s5o71pSR7PW6XJuNG++GNR+HV7zn3u9V8yAluS9a4XdklQwFOREREROLamb4Rvv1CM//SeIy0JA9fubGGz19TQUaq3srGjdEB2PUjeOW7MNwF1Tc7wa14rduVXXL0qhcRERGRuNQ34ufRl1p5/OVDBEIhfntjOfddV0VhONmSKQAAIABJREFUZqrbpcm4sUHY9Ti88h0Y6oSqG2Drn0PJOrcru2QpwImIiIhIXBkNBHly51G+96tmuof83HrFEr56Uw3lBRlulybjxoag8QknuA22Q+V1sPXPoHSD25Vd8hTgRERERCQuhEKW//jvEzz43AGOdQ2zuaqAb2xbwWUlOW6XJuP8w9D4Y3j52zB4BpZtdVbcyq5yu7J5QwFORERERFy3o7md+5/Zz94TfaxcnM0/3nMZ9dWF6iwZL/wj8OY/wI6HYOAULK2HT/4DlG9yu7J5RwFORERERFzz7vFe7n9mPy+3dFCSl8537ljDbVcsweNRcIsLgVF48x+d4NZ/AsqvgY8/DkuvcbuyeWtGAc4Ysw14GPACj1lr75/y/O8BXwKCwABwr7X2vfBzfwZ8PvzcH1prn5298kVEREQkER3tHOLB5w7w9NsnyFuQzP+4ZSV3bywjNcnrdmkCTnDb809OcOs7DmWb4Dd/CBVb3K5s3rtggDPGeIFHgBuBNmCXMebp8YAW9hNr7d+Fz78NeAjYZoxZCdwJrAKWAC8YY2qstcFZ/nuIiIiISALoHBjle79q4cnXj+D1GO67top7G5aRnZbsdmkCEBiDt56E7Q9CXxuUXgW3P+Lc66btrHFhJitwG4AWa20rgDHmKeB2YCLAWWv7os7PAGz469uBp6y1o8AhY0xL+M97bRZqFxEREZEEMTQW4PEdh/jh9laG/UE+WVfKl2+opig7ze3SBCDoh7d+4gS33qNQsh5u+67TXVLBLa7MJMAVA8eiHrcBZ7WZMcZ8CfgKkAJcF3XtzinXFk9z7b3AvQBlZWUzqVtEREREEoA/GOL/7jrGw79spr1/lJtXFfG1m5dTtTDT7dIEnOD29lOw/QHoOQLF6+CWb0PV9QpucWrWmphYax8BHjHG3AX8JfCZ93Hto8CjAHV1dfYCp4uIiIhInAuFLM/uPcUDzx6gtWOQuvI8/u7utawrz3e7NAEIBuCdf4GXvgXdh2DJlfDhB6D6JgW3ODeTAHccKI16XBI+di5PAT/4gNeKiIiISILqGBhlR3M7Lx1oZ0dzB52DY1QvzOSxT9dx/YqFGgkQD4IBePdnTnDrOgiLLodPPQU12xTcEsRMAtwuoNoYU4ETvu4E7oo+wRhTba1tDj/8DWD866eBnxhjHsJpYlINvDEbhYuIiIiIuwLBEHuO9fDSgXZeamrnneO9AORnpLClupDrVxTxodWLSPJ6XK5UCAXh3X+Dl/4GOlug6DK48ydQ+2EFtwRzwQBnrQ0YY+4DnsUZI/CEtXavMeabQKO19mngPmPMDYAf6Ca8fTJ83r/gNDwJAF9SB0oRERGRxHWiZ5jtTU5ge7mlg/6RAF6PYW1ZLl+9qYYtNT5WL8nRHLd4EQrC3v/nBLeOJli4Cj75T7D8FvAoWCciY2183XJWV1dnGxsb3S5DRERERIDRQJBdh7p5qekMLzW103R6AIDFOWk01PhoqPGxqaqQnHSNAYgroRC89+9OcGvfD74VsPUbsOI2BbcEYIzZba2tm+65WWtiIiIiIiKXhsMdg7wUXmV77WAnw/4gKV4PGyry+cS6UhpqfVQvzNQ9bfEoFIJ9TzvB7cx74FsOH/8xrPyIgtslQgFOREREZJ4bHA2ws7VzIrQd6RwCYGnBAj5ZV0JDrY+NywpYkKK3jnHLWtj/n/Di/XD6XSisgY89Dqs+Ch6v29XJLNJ/hSIiIiLzjLWWptMDE9sidx3qZiwYIj3Zy6bKAj5/TQVbqn0sLcxwu1S5EGvhwH/Bi38Np96Bgir4zR/B6o8puF2iFOBERERE5oHeYT+vtHRMdIw81TcCQG1RFp/dvJSGGh91S/NITdKb/oRgLTT9wgluJ9+G/GXw0R/C6o+DV2/xL2X6tysiIiJyCQqFLO+e6J0IbHuO9RAMWbLSkqivLqShxseWGh+Lc9LdLlXeD2uh+Xl48X/DiT2QtxQ+8gO47JMKbvOE/i2LiIiIXCKiB2lvb+6ga3AMgMtLcvji1koaanysKc2d+7ls1kL7AWdlyIbm9nvNJ8FRePOf4Hgj5JbBbd+HK+4ErzqAzicKcCIiIiIJ6lyDtAsyUiZa/F9TXUhhZurcFzM2CIe2Q/Nz0PwC9B6d++85H+WUwa3fhTV3KbjNUwpwIiIiIgnkRM+w0y3yQDuvHIwM0l5XlsfXbq6locbHysXZsRmk3XkwHNieg8MvQ3AMkjOg8lrY8idQdjV4U+a+jvkkp0TBbZ5TgBMRERGJYyP+ILsOd02ssjWfiQzSvuXyxTTU+Li6MkaDtP3DcPgVJ7C1PA9drc7xwlrYcC9U3+iEtqQYrPiJzFMKcCIiIiJxxFrL4c4hXjrgtPh/rbWTEX+IFK+Hq5blc8f6UhpqfFTFapB292GnaUbz884WycAwJKVDxRbY+EUntOUtnfs6RARQgBMRERFx3eBogNcORgZpH+1yBmlXFGZw5/oyGmp8XLUsPzaDtAOjcPS1cGh7DjqanON5FbDuM05gK98MyepeKeIGBTgRERGRGLPWcuB0/8S2yF2Hu/AHLQtSnEHaX6ivYEuNj/KCGA3S7m2LWmV7CcYGwJsKS6+Bunug+iYoqIxNLSJyXgpwIiIiIjHQO+Tn5ZYOXmpytkae7hsFYPmiLO7ZXEFDjY91sRqkHfTDsTfCDUiehzN7neM5ZXD5HU5gq6iHlBgFSBGZMQU4ERERkTkQClneOd47sS1yz9FuQhay05Kor/ZNDNJelJMWm4L6T0HLC05oO/gijPaCJwnKN8FNfwVVN4KvFmJxX52IfGAKcCIiIiKzpL0/PEi7qZ0d4UHaxsDlxTncd20VDbU+riiJwSBtgFAQ2hqdbpHNzzlDtQGyFsOq28OrbA2Qlj33tYjIrFGAExEREfmA/MEQbx7pZns4tL17vA+AwswUttb4aKj1cU1VIQWxGKQNMNgBLb8Mr7L9Eoa7wXih9Cq4/n86oa1olVbZRBKYApyIiIjI+3C8ZzjcfOQMr7Z00j/q4iDtUAhO7ol0jDz+JmAhYyHUfhiqbnCGaqfnzX0tIhITCnAiIiIi5zHiD/LGoa6Je9lawoO0l+SkccsVziDtTVWFZKfFYJA2wFAXHPxV+H6252GoAzBQUgfX/rnT5n/RFeCJwTZNEYk5BTgRERGRKNZaDnUMTgS2neODtJM8XFWRz53rS9la66PSF6NB2tbCqXciHSPb3gAbgvR8Z4Wt+iaovA4yCua+FhFxnQKciIiIzHv9I352tnZNtPg/1jUMwLLxQdq1PjZWFJCeEoMW/wAjvdD6Yji0vQADp5zjS66E+q86oa14LXhiVI+IxA0FOBEREZl3guEW/zvC3SLfPNpNIDQ+SLuQe7dU0lDto6xgQWwKshbO7At3jHwejr4GoQCk5kDVdU5gq7oBMhfGph4RiVsKcCIiIjIvnOgZZkdzO9ubO3ilpYOeIT8Aq4uz+cKWZdRXF1JXnk9KUozuHRsdgEPbI1sj+9qc40WXwaY/dEJbyXrw6u2aiETM6CeCMWYb8DDgBR6z1t4/5fmvAL8DBIB24B5r7ZHwc0HgnfCpR621t81S7SIiIiLnNDga4PVDnWxv6mBHczsH2wcBKMpO5YYVRdRXF8a2xb+10NkSDmzPwZFXITgGKVlQuRUavu40IMleEpt6RCQhXTDAGWO8wCPAjUAbsMsY87S19r2o0/YAddbaIWPM7wPfAu4IPzdsrV0zy3WLiIiITBIKWd472cf25na2N7Wz+0g3/qAlLdnDVRUFfGpDGVtqfFQvjFHzEQD/MBx+ORLaug87x33L4arfdVbZSjdCUkps6hGRhDeTFbgNQIu1thXAGPMUcDswEeCstb+OOn8ncPdsFikiIiIynVO9I+xodu5je7mlg67BMQBWLM7mns0V1Ff7qFuaR1pyDJt9dB2KzGU7vAMCI5C8ACoaYNMfQNWNkFceu3pE5JIykwBXDByLetwGXHWe8z8PPBP1OM0Y04izvfJ+a+2/T73AGHMvcC9AWVnZDEoSERGR+Wh4LMgbh7vY3tTOjuZ2mk47M9kKM1PZWuOjvqaQzVWFLMxKi11RgVE48orTLbL5Oehsdo7nV8K6zznbIss3Q3IMaxKRS9as3hVrjLkbqAMaog6XW2uPG2OWAb8yxrxjrT0YfZ219lHgUYC6ujo7mzWJiIhI4rLWsu9k/8Qq2xuHuxgLODPZNizN5+PrSqiv9rF8UVbstkUC9ByLdIxsfQn8g+BNhYp62PAFp2NkQWXs6hGReWMmAe44UBr1uCR8bBJjzA3AXwAN1trR8ePW2uPhz63GmBeBK4GDU68XERERATjTP8LLzR3sCH90DDhvK2qLsvj0xnLqa3xsWJofu5lsAEE/HN0Z6RjZvs85nlsGa+5yVtmW1kNKjMYOiMi8NZMAtwuoNsZU4AS3O4G7ok8wxlwJ/BDYZq09E3U8Dxiy1o4aYwqBzTgNTkREREQAGPEHaTzcPdHif9/JPgDyM1Kory6kvtpHfXUhRdkx3oLYdxJawtsiW1+E0T7wJEP5JrjybqcBSWE1xHLlT0TmvQsGOGttwBhzH/AszhiBJ6y1e40x3wQarbVPAw8AmcC/hrcvjI8LWAH80BgTAjw498C9N+03EhERkXnBWkvT6YGJwPZ6ayejgRDJXkNdeT5f31bLlmofKxdn4/HEMBwFA3C8MdIx8lR4ClJ2Maz+TSewVWyB1KzY1SQiMoWxNr5uOaurq7ONjY1ulyEiIiKzqHNglJdbOiZmsp3pd7ZFVi3MpL66kC3VPq5als+ClBgOrR5odwJbWyO07YITe5xVNuOFsquh+gYntC1cqVU2EYkpY8xua23ddM/F8KekiIiIzBejgSC7j3SH72Nr593jzrbI3AXJbK4qZEt4a+SS3PTYFOQfcVbU2nZFQlvPEec544VFq+GyTzgrbMu2QnpubOoSEXmfFOBERETkollrOdg+MLHCtrO1i2F/kCSPYW15Hl+9qYb6ah+ri3PwzvW2SGuhqxWO746srp16B0J+5/nsEihZ53SLLK6DxVeo+YiIJAwFOBEREflAugfHeOVgBzvCoe1E7wgAywoz+GSd095/Y2UBmalz/HZjuCcS1sZX14a7nOeSM2DJlXD1l6Ckzgls2Yvnth4RkTmkACciIiIzMhYIsedoZFvkfx/vxVrISkvimqpC7rvO6RZZmj+Hq1nBAJzZ66yqte12Po8PzsaAbzks/7AT1ErWO4+9ersjIpcO/UQTERGRaVlrOdw55HSLbOrgtYMdDI4F8XoMV5bm8uXra6ivKeTy4hySvJ65KAD6jk9eWTvxFgSGneczfE5Qu+JOZ3VtyVpIy579OkRE4ogC3Ewc3Qn/+lm3qxC5AOO8cUnPg/T88OdcWJA/+Vj04+R0dVYTkUl6h/y8erCD7eFVtrZuJyyV5qfzkSuLqa/2samqgOy05Nn/5qMDcPKt8Opao7Mtsv+k85w3xblXre5zULzOWV3LLdPPMBGZdxTgZiI9H6pvdLsKkfOzIRjpg+Fup7PaiT3O1+O/qZ6ON3VKwMs9O+RN9zg5xsN0RWTOBIIh3m7rYXtTB9ub23n7WA8hC5mpSWyqLOB3GyrZUl1IeUHG7H7jUAg6DkxeXTvznvOzDCCvApbWOytrJXVQdBkkpcxuDSIiCUgBbiZ8NXDb99yuQuSD8Q87QW64G4a6wl93TXkc/uhqDR/rguDYuf/M5AXvP/Sl5+nNl0icONo5xPbmdnY0t/NqSyf9owE8Bi4vyeW+a6uor/GxpjSX5NncFnmumWsAaTnOqlrth52VteJ1kFEwe99bROQSogAncqlLTnc+spfM/BprwT90gdDXEznWfiByTihw7j83JTMS5mYa+tLz1IBA5CL1j/h59WAnO5rb2dHcwZHOIQCKc9O55YrFzrbIygJyF8zSL1kuNHOtaJUzc228K2RBFXjm4B46EZFLkN4VicjZjIGUDOcjp2Tm11kLYwPnCH09Zx879W7k8fi2qemkZs8g9E05lpYDHu/F/7MQSUDBkOW/23omukW+ebSHYMiyIMXLpsoC7tlcQX11IRWFGZiLvYfsgjPXip2gtv53nM+L12jmmojIRVCAE5HZYwykZjkfeeUzvy4UcrZSRQe84Z5zr/51H46cgz1XMU6IO9fK3llBMHw8NUcrAZKQ2rqHJgLbKy2d9A77MQYuK87h9xqWUV/tY21ZHilJF/n6ntHMtS+Gt0Jq5pqIyGxTgBMR93k84XvpcoGKmV8XCsJI7+T7+M4V+oY6obMFhrphtPfcf6bxQFq4e2d2caTbXUkdZC686L+qyGwIBEOc7h9l/8k+djR3sL2pndaOQQAWZadx86oi6qt9bK4qJD/jIrZFXnDmWm34vrVwoxHfCm15FhGZY/opKyKJy+N1gtaC/Pd3XTAQDn5T7+ub8rjrILz63ch9fTllkTeqJeth0eXqyCmzzlpL95CfEz3DnOgZ5mTvCCd6hjke9fXpvhFC4cXntGQPG5cV8Fsby2moKaTSl/nBtkVeaObagkLndX/FHc7KWvFaZ5VbRERiSgFOROYfb5LT4W4mXe78w3Dy7ci9PW27YO/Pnec8ybBodWSrWEkd5C/TXCo5r6GxACd6RjjZOxwOaSOTgtqJ3mFG/JPvCU3xelicm8aSnHSuriygODedxTnpVBRmsLY8l9SkD3C/50xmrq37bOSXFrnlem2LiMQBY+257h9xR11dnW1sbHS7DBGRc+s/NXmV4vib4He2r5GeH952GX7TW7zOubdO5oXxrY0np6yYjYe0E73D9Az5J11jDCzMSmVxTno4mKWxJDedJbnO58U56RRkpODxXER4msnMtfGV5eI65xcTSakX8U9CREQuhjFmt7W2btrnFOBERC5SKAjt+yevZJzZx0SDlYKqyGyrkjooWg3eZFdLlvdv6tbG8VWzc21tHJedlhQOZFPCWY5zrCg77eIbi0x1vplrqTnO9sfxezuL10FG4ex+fxERuSgKcCIisTbS57xpbtsV6dg3eMZ5LinNaaU+sUpX54xr0PY0V13s1sbJq2ZpzmpabjqZqXN8t8JMZq6Nv85K1mvmmohIAlCAExFxm7XQczT8Bjvcze/k2xAcdZ7PXBRZDSlZ77RiT810t+ZLyLm3NoaDmltbG9+PsUHoOuQ01+k86Hw+/d7ZM9eiO6dq5pqISEI6X4BTExMRkVgwxpmNl1cOqz/mHAuMwel3J9+XtP8/w+d7nJbs0V0vC2s0nHwas7G1cW157llBbU62Nl6If/jskNbZ6nwebzAyLmOh85q4+ouRJjrZS2Jbr4iIxJxW4ERE4slQV3jL5a5IsBsJz61LyYLiKyd3vZwHs+k+0NbGJA9LctJY7ObWxnMJjE4Jaa2RoNbXNvncBQWQXwkFleHPy5zP+csgLdud+kVEZM5pC6WISKIKhZw39xOrdLvg9N7IbLrcskiYS8DZdFO3Np4V1M6ztXFJbnr43rOzg1pBRsoHm4U2WwJjzn1oE6toUatpvceYaHADTpfSSSGtEvIrnK/Tc137K4iIiHsuOsAZY7YBDwNe4DFr7f1Tnv8K8DtAAGgH7rHWHgk/9xngL8On/pW19h/O970U4ERELmBsyLl/bqLLYGNk5SYOZ9N1D45x4HQ/zaf7aes+90DqcdFbG8fDmetbG6cT9Dv3NU4NaV2tznEbtSqYlhNZOZsU1Ja9/0H0IiJyybuoAGeM8QJNwI1AG7AL+JS19r2oc64FXrfWDhljfh/Yaq29wxiTDzQCdTi/btwNrLPWdp/r+ynAiYh8AOOz6ca7Xk47m249lKybs9l0Q2MBmk4P0HSqnwOn+2k63c/+U/20949OnDN1a2NxbhqLx8NaTpq7WxunEwxA71EnlI3fizYe1LqPgA1Gzk3JimxxnBTSKp2Qpi6jIiIyQxfbxGQD0GKtbQ3/YU8BtwMTAc5a++uo83cCd4e/vhl43lrbFb72eWAb8NP3+5cQEZHzyFoEK25xPsCZTXdm3+RVupYXiMymq57c9bJo1Yxn040FQhzqGHRC2iknpDWd7udo19DEOWnJHmqKsmio8VFblEXtoixqirIoyk51d2vjdEJB6G2bfE9adEgLRW3hTM5wQtqiy2HVR50VtPGgluFTSBMRkTk3kwBXDByLetwGXHWe8z8PPHOea4unXmCMuRe4F6CsrGwGJYmIyHl5vM5WykWrYd1nnWMjfXDizciw8ZYX4O3w79OmmU0XyiqmrWeEA6f7OXCqjwPh1bXWjgH8QScIej2GZYUZXFaSwyfWlVCzKIvaoixK8xfgjVV7/ZkIhaDv+JTGIeGg1n0IgmORc5PSnWC2cAUsv2XyalpmkUKaiIi4alb3qRhj7sbZLtnwfq6z1j4KPArOFsrZrElERMLSsmHZVucDJmbT2bZGhg/tJHB0Fwtef5Sk174PQIfNY1+okj2hKt6yVXRmr6R88UKuX7GQ2kXOqlpFYQapSXEy2sBap9X+pHvSokJaYCRyblIa5FVAYTXU3Dw5pGUtVkgTEZG4NZMAdxwojXpcEj42iTHmBuAvgAZr7WjUtVunXPviBylUREQuXu+wn+bT/VO2P2bRPbQV2EoyAa7OOMl1WUdY62lh08h+bh4K35c86oGhlTC2DkJ14FkPntrY/gWshYHT03d37GqFwHDkXG+KE9IKKqHq+kjTkPxKZ+C1Jw4aoYiIiLxPM2likoTTxOR6nEC2C7jLWrs36pwrgZ8B26y1zVHH83Eal6wNH3oTp4lJ17m+n5qYiIhcvBF/kJYzAxwI3582HthO9EZWoTJTk6gpynRW04qyJrY/FmSmTv7DBjvDjVEazzGbbu3EtstZmU1nLQy2T5mRNt7h8RCMDUTO9SRD3tKo7o5RXR5zSjT4XEREEtJFNTGx1gaMMfcBz+KMEXjCWrvXGPNNoNFa+zTwAJAJ/Gv45vSj1trbrLVdxpj/hRP6AL55vvAmIiLvTyAY4nDnkBPSxsPaqX4Odw5OtOdP8XqoXJjJVcsKqCnKonZRJrWLslmSkzazhiIZBVBzk/MBUbPpooaNv/ydSEfGidl0651AN91sOmudoeWTVtGiQtpoX+Rc44W8cieUlW+ePNA6pxS8cdS1UkREZI5pkLeISAKw1nKid2SiRf+BU85HS/sAYwFn3pjHwNKCDGrCq2nLw50flxYsIMk7x9sFJ82m2wVtu6fMprsMlqyB0f5IUBtfxQMwHif4Rc9HG/86t2zGHTJFREQuBRc7RkBERGKoa3AsHNDCnR/D2x/7RwMT5yzOSaOmKIv66sLwqloWVQszSUt2actgygIov9r5GNd3Mmrb5W5452eQluusnq3++OTGIbnlkJTiTu0iIiIJRAFORMQlg6MBJ5yd7ufAqYGJwdcdA5HB17kLkqktyuKja4upKXJW1aqLsshJT4AVqezFkH0rrLjV7UpEREQuGQpwIiJzbCwQorVjYNI9agdO93OsK9IxMT3ZS01RJtfW+iZa9NcWZeHLisPB1yIiIuIaBbgZ6B3y897JvgufKOKylCRDitdLarKHFK+HlCQPqUnjn70ke43CwBwKhSzHuoec1vzhkNZ0up/W9kEC4Y4iSR7DMl8Ga0rzuKOudGL7Y2neAjzxNPhaRERE4pIC3AzsPdnLXT963e0yRGbFeKhLDYe6lCQn7J0r9KUknX0sddprvJPOu9D3mfOmGnPIWkt7/2h4hlpkRa359ADD/uDEeWX5C6gpyuLGlUXh7Y/ZVBRmkJKUuH93ERERcZcC3AysWpzDT7+w0e0yRM7LYvEHLWOBEGOBEKOBYPiz83gsGGLUH2Q0GJp03Pk8+dz+kcCka8aCznPjz88Gj+Ecoc87KfxFh77pAuX5r5l+NXJqED3fylfvsD8S0qJW1XqG/BPn+LJSqS3K4lMbypzOj4uyqF6YSUaqfsSKiIjI7NK7ixnIWZDM1ZUFbpchEhestYyFQ+DZATHEWDDIqD80TVAMnuOa4MS1k68JMjgaoOs81/iDszMGJdlrwqHPOykwDowGOBk1+DorNYnaRVl8+LLFzuDr8PbH/Ax1TxQREZHYUIATkffFGBNevXKpXX2UUMhGrQ6eHRAjoS8YDpeTVxKnvyY4ERTTkrzURDUUWTzTwdciIiIic0QBTkQSlsdjSPN4w7PPEqCtvoiIiMhF0p30IiIiIiIiCUIBTkREREREJEEowImIiIiIiCQIBTgREREREZEEoQAnIiIiIiKSIBTgREREREREEoSxdnYG4c4WY0w7cMTtOqZRCHS4XYTIBeh1KvFOr1GJd3qNSrzTa3R+KLfW+qZ7Iu4CXLwyxjRaa+vcrkPkfPQ6lXin16jEO71GJd7pNSraQikiIiIiIpIgFOBEREREREQShALczD3qdgEiM6DXqcQ7vUYl3uk1KvFOr9F5TvfAiYiIiIiIJAitwImIiIiIiCQIBTgREREREZEEoQA3A8aYbcaYA8aYFmPMN9yuRySaMabUGPNrY8x7xpi9xpg/crsmkekYY7zGmD3GmP90uxaRqYwxucaYnxlj9htj9hljrna7JpFoxpg/Dv9//l1jzE+NMWlu1yTuUIC7AGOMF3gE+BCwEviUMWalu1WJTBIA/sRauxLYCHxJr1GJU38E7HO7CJFzeBj4hbV2OXAFeq1KHDHGFAN/CNRZa1cDXuBOd6sStyjAXdgGoMVa22qtHQOeAm53uSaRCdbak9baN8Nf9+O86Sh2tyqRyYwxJcBvAI+5XYvIVMaYHGAL8DiAtXbMWtvjblUiZ0kC0o0xScAC4ITL9YhLFOAurBg4FvW4Db05ljhljFkKXAm87m4lImf5DvB1IOR2ISLTqADagR+Ht/k+ZozJcLsokXHW2uPAg8BR4CTQa619zt2qxC0KcCKXCGNMJvBvwJettX1u1yMyzhhzC3DGWrvb7VpEziEVMpsoAAABcElEQVQJWAv8wFp7JTAI6J53iRvGmDycHWAVwBIgwxhzt7tViVsU4C7sOFAa9bgkfEwkbhhjknHC25PW2p+7XY/IFJuB24wxh3G2oV9njPlnd0sSmaQNaLPWju9e+BlOoBOJFzcAh6y17dZaP/BzYJPLNYlLFOAubBdQbYypMMak4Nww+rTLNYlMMMYYnPs29llrH3K7HpGprLV/Zq0tsdYuxfkZ+itrrX5zLHHDWnsKOGaMqQ0fuh54z8WSRKY6Cmw0xiwI/3//etRoZ95KcruAeGetDRhj7gOexen484S1dq/LZYlE2wz8NvCOMeat8LE/t9b+l4s1iYgkmj8Angz/srYV+JzL9YhMsNa+boz5GfAmTvfpPcCj7lYlbjHWWrdrEBERERERkRnQFkoREREREZEEoQAnIiIiIiKSIBTgREREREREEoQCnIiIiIiISIJQgBMREREREUkQCnAiIiIiIiIJQgFOREREREQkQfx/2XQxk99YJS0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (0.1, 0.001, 0.99, 128, 10, 128, 0.99)\n",
    "loss_history, train_history, val_history = best_history\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как модель натренированная на части тренировочных данных работает на тестовых"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.335000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Натренируем модель с полученными гиперпараметрами и посмотрим как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.284597, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236123, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262188, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266556, Train accuracy: 0.199000, val accuracy: 0.208000\n",
      "Loss: 2.247847, Train accuracy: 0.230667, val accuracy: 0.222000\n",
      "Loss: 2.227358, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.169841, Train accuracy: 0.231889, val accuracy: 0.240000\n",
      "Loss: 2.077013, Train accuracy: 0.300222, val accuracy: 0.325000\n",
      "Loss: 1.945799, Train accuracy: 0.349889, val accuracy: 0.360000\n",
      "Loss: 1.800736, Train accuracy: 0.415556, val accuracy: 0.417000\n",
      "Loss: 1.657235, Train accuracy: 0.503778, val accuracy: 0.501000\n",
      "Loss: 1.562435, Train accuracy: 0.553111, val accuracy: 0.557000\n",
      "Loss: 1.499474, Train accuracy: 0.581444, val accuracy: 0.565000\n",
      "Loss: 1.473542, Train accuracy: 0.611222, val accuracy: 0.589000\n",
      "Loss: 1.487131, Train accuracy: 0.623556, val accuracy: 0.597000\n",
      "Loss: 1.440747, Train accuracy: 0.637222, val accuracy: 0.609000\n",
      "Loss: 1.472662, Train accuracy: 0.649222, val accuracy: 0.614000\n",
      "Loss: 1.443251, Train accuracy: 0.668111, val accuracy: 0.637000\n",
      "Loss: 1.424924, Train accuracy: 0.691111, val accuracy: 0.643000\n",
      "Loss: 1.396902, Train accuracy: 0.695000, val accuracy: 0.649000\n",
      "Loss: 1.404141, Train accuracy: 0.697778, val accuracy: 0.660000\n",
      "Loss: 1.374170, Train accuracy: 0.709556, val accuracy: 0.662000\n",
      "Loss: 1.362350, Train accuracy: 0.707333, val accuracy: 0.660000\n",
      "Loss: 1.347575, Train accuracy: 0.723556, val accuracy: 0.650000\n",
      "Loss: 1.326367, Train accuracy: 0.735333, val accuracy: 0.666000\n",
      "Loss: 1.295627, Train accuracy: 0.756111, val accuracy: 0.695000\n",
      "Loss: 1.285026, Train accuracy: 0.747000, val accuracy: 0.687000\n",
      "Loss: 1.280384, Train accuracy: 0.745556, val accuracy: 0.693000\n",
      "Loss: 1.267403, Train accuracy: 0.761000, val accuracy: 0.709000\n",
      "Loss: 1.240977, Train accuracy: 0.776000, val accuracy: 0.708000\n",
      "Loss: 1.212194, Train accuracy: 0.755111, val accuracy: 0.695000\n",
      "Loss: 1.195376, Train accuracy: 0.767556, val accuracy: 0.694000\n",
      "Loss: 1.186678, Train accuracy: 0.790778, val accuracy: 0.706000\n",
      "Loss: 1.169871, Train accuracy: 0.770444, val accuracy: 0.685000\n",
      "Loss: 1.170775, Train accuracy: 0.777556, val accuracy: 0.676000\n",
      "Loss: 1.146093, Train accuracy: 0.776889, val accuracy: 0.701000\n",
      "Loss: 1.134171, Train accuracy: 0.776222, val accuracy: 0.692000\n",
      "Loss: 1.139377, Train accuracy: 0.777444, val accuracy: 0.694000\n",
      "Loss: 1.141010, Train accuracy: 0.786778, val accuracy: 0.697000\n",
      "Loss: 1.103448, Train accuracy: 0.792667, val accuracy: 0.700000\n",
      "Loss: 1.092956, Train accuracy: 0.819889, val accuracy: 0.725000\n",
      "Loss: 1.065692, Train accuracy: 0.798222, val accuracy: 0.695000\n",
      "Loss: 1.085778, Train accuracy: 0.793333, val accuracy: 0.699000\n",
      "Loss: 1.089832, Train accuracy: 0.782111, val accuracy: 0.686000\n",
      "Loss: 1.097606, Train accuracy: 0.773000, val accuracy: 0.699000\n",
      "Loss: 1.127423, Train accuracy: 0.774000, val accuracy: 0.692000\n",
      "Loss: 1.116931, Train accuracy: 0.790778, val accuracy: 0.688000\n",
      "Loss: 1.132210, Train accuracy: 0.760889, val accuracy: 0.685000\n",
      "Loss: 1.176914, Train accuracy: 0.771000, val accuracy: 0.694000\n",
      "Loss: 1.171488, Train accuracy: 0.761778, val accuracy: 0.680000\n",
      "Loss: 1.147227, Train accuracy: 0.777667, val accuracy: 0.690000\n",
      "Loss: 1.134357, Train accuracy: 0.773333, val accuracy: 0.686000\n",
      "Loss: 1.196097, Train accuracy: 0.772222, val accuracy: 0.694000\n",
      "Loss: 1.154387, Train accuracy: 0.778111, val accuracy: 0.694000\n",
      "Loss: 1.132897, Train accuracy: 0.794333, val accuracy: 0.713000\n",
      "Loss: 1.135624, Train accuracy: 0.777556, val accuracy: 0.689000\n",
      "Loss: 1.112016, Train accuracy: 0.779111, val accuracy: 0.683000\n",
      "Loss: 1.143237, Train accuracy: 0.790333, val accuracy: 0.727000\n",
      "Loss: 1.087045, Train accuracy: 0.820222, val accuracy: 0.728000\n",
      "Loss: 1.065600, Train accuracy: 0.806111, val accuracy: 0.713000\n",
      "Loss: 1.069307, Train accuracy: 0.804333, val accuracy: 0.725000\n",
      "Loss: 1.055752, Train accuracy: 0.808333, val accuracy: 0.714000\n",
      "Loss: 1.053406, Train accuracy: 0.818000, val accuracy: 0.722000\n",
      "Loss: 1.038478, Train accuracy: 0.808333, val accuracy: 0.711000\n",
      "Loss: 1.044510, Train accuracy: 0.799333, val accuracy: 0.711000\n",
      "Loss: 1.052392, Train accuracy: 0.816222, val accuracy: 0.728000\n",
      "Loss: 1.036838, Train accuracy: 0.813556, val accuracy: 0.727000\n",
      "Loss: 1.021669, Train accuracy: 0.824111, val accuracy: 0.737000\n",
      "Loss: 0.997502, Train accuracy: 0.821556, val accuracy: 0.737000\n",
      "Loss: 0.990066, Train accuracy: 0.832556, val accuracy: 0.749000\n",
      "Loss: 0.957206, Train accuracy: 0.822667, val accuracy: 0.721000\n",
      "Loss: 0.955871, Train accuracy: 0.835444, val accuracy: 0.758000\n",
      "Loss: 0.940209, Train accuracy: 0.841333, val accuracy: 0.726000\n",
      "Loss: 0.929309, Train accuracy: 0.839556, val accuracy: 0.739000\n",
      "Loss: 0.945191, Train accuracy: 0.843778, val accuracy: 0.739000\n",
      "Loss: 0.918820, Train accuracy: 0.847111, val accuracy: 0.745000\n",
      "Loss: 0.924873, Train accuracy: 0.840333, val accuracy: 0.739000\n",
      "Loss: 0.909080, Train accuracy: 0.849667, val accuracy: 0.746000\n",
      "Loss: 0.889576, Train accuracy: 0.852111, val accuracy: 0.737000\n",
      "Loss: 0.888431, Train accuracy: 0.849222, val accuracy: 0.745000\n",
      "Loss: 0.888290, Train accuracy: 0.852444, val accuracy: 0.743000\n",
      "Loss: 0.882417, Train accuracy: 0.852000, val accuracy: 0.739000\n",
      "Loss: 0.870429, Train accuracy: 0.864222, val accuracy: 0.756000\n",
      "Loss: 0.870647, Train accuracy: 0.851556, val accuracy: 0.737000\n",
      "Loss: 0.874574, Train accuracy: 0.845444, val accuracy: 0.740000\n",
      "Loss: 0.891584, Train accuracy: 0.859333, val accuracy: 0.739000\n",
      "Loss: 0.887768, Train accuracy: 0.854556, val accuracy: 0.756000\n",
      "Loss: 0.864380, Train accuracy: 0.854778, val accuracy: 0.750000\n",
      "Loss: 0.861976, Train accuracy: 0.857778, val accuracy: 0.737000\n",
      "Loss: 0.868326, Train accuracy: 0.860889, val accuracy: 0.733000\n",
      "Loss: 0.854592, Train accuracy: 0.871444, val accuracy: 0.747000\n",
      "Loss: 0.854059, Train accuracy: 0.849667, val accuracy: 0.736000\n",
      "Loss: 0.866234, Train accuracy: 0.860333, val accuracy: 0.758000\n",
      "Loss: 0.873432, Train accuracy: 0.861556, val accuracy: 0.741000\n",
      "Loss: 0.868848, Train accuracy: 0.875444, val accuracy: 0.751000\n",
      "Loss: 0.869240, Train accuracy: 0.868333, val accuracy: 0.769000\n",
      "Loss: 0.868612, Train accuracy: 0.857889, val accuracy: 0.741000\n",
      "Loss: 0.864791, Train accuracy: 0.849333, val accuracy: 0.728000\n",
      "Loss: 0.876651, Train accuracy: 0.864778, val accuracy: 0.742000\n",
      "Loss: 0.871768, Train accuracy: 0.847778, val accuracy: 0.744000\n"
     ]
    }
   ],
   "source": [
    "best_clf = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size=128, reg=1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(best_clf, dataset, MomentumSGD(momentum=0.99), num_epochs=100, \n",
    "                  batch_size=1024, learning_rate=1e-1, learning_rate_decay=0.99)\n",
    "    \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.708000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_clf.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
